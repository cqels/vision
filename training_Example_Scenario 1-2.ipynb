{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, JSON, POST\n",
    "import json, os \n",
    "from query_util_redundancy_filter import *\n",
    "import sys\n",
    "query_file   = 'query2-image_without_annotation_reproduce.sparql'\n",
    "query_string = open(query_file,'r').read()\n",
    "file_anno    = 'mmdetection/data/mixedDataset/annotations/instances_train2017_1.json'\n",
    "dataset = process_query(query_string)\n",
    "with open(file_anno,'w') as outfile:\n",
    "    json.dump(dataset,outfile)\n",
    "    \n",
    "categories = [category['name'] for category in dataset['categories']]\n",
    "\n",
    "number_of_categories = len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from check_annotation.ipynb\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import funcy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import Ipynb_importer\n",
    "from check_annotation import print_instances_class_histogram\n",
    "\n",
    "def save_coco(file, images, annotations, categories):\n",
    "    print_instances_class_histogram(file, annotations, [category['name'] for category in categories])\n",
    "    with open(file, 'wt') as coco:\n",
    "        json.dump({'images': images, 'annotations': annotations, 'categories': categories}, coco, indent=2,\n",
    "                  sort_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_annotations(annotations, images):\n",
    "    image_ids = funcy.lmap(lambda i: int(i['id']), images)\n",
    "    return funcy.lfilter(lambda a: int(a['image_id']) in image_ids, annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_split(annotation_file, path_to_train, path_to_test, ratio):\n",
    "    with open(annotation_file, 'rt') as annotations:\n",
    "        coco = json.load(annotations)\n",
    "        images = coco['images']\n",
    "        annotations = coco['annotations']\n",
    "        categories = coco['categories']\n",
    "\n",
    "        images_with_annotations = funcy.lmap(lambda a: int(a['image_id']), annotations)\n",
    "        images = funcy.lremove(lambda i: i['id'] not in images_with_annotations, images)\n",
    "\n",
    "        train, test = train_test_split(images, train_size=ratio)\n",
    "\n",
    "        save_coco(path_to_train, train, filter_annotations(annotations, train), categories)\n",
    "        save_coco(path_to_test, test, filter_annotations(annotations, test), categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "path_to_train_val = 'mmdetection/data/mixedDataset/annotations/instances_train_val2017_person_pedestrian.json'\n",
    "path_to_train = 'mmdetection/data/mixedDataset/annotations/instances_train2017_person_pedestrian.json'\n",
    "path_to_val = 'mmdetection/data/mixedDataset/annotations/instances_val2017_person_pedestrian.json'\n",
    "path_to_test = 'mmdetection/data/mixedDataset/annotations/instances_test2017_person_pedestrian.json'\n",
    "ratio = 0.85\n",
    "with open(path_to_val) as json_object:\n",
    "    categories_dict =json.load(json_object)\n",
    "categories= [category['name'] for category in categories_dict['categories']]\n",
    "number_of_categories=len(categories)\n",
    "dataset_split(file_anno, path_to_train_val, path_to_test, ratio)\n",
    "dataset_split(path_to_train_val, path_to_train, path_to_val, ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.bbox_head.num_classes: classes number of extracted datasets\n",
    "\n",
    "# data.samples_per_gpu: * gpu = batch size\n",
    "\n",
    "# other parameters can also be set here and then mergerd into the file \"***loadFromSeparatedFile.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new training pipeline on the coco-kitti mixedDataset with categories pedestrian and person_setting(person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run mmdetection/tools/train.py \\\n",
    "mmdetection/configs/fcos/fcos_r50_caffe_fpn_gn-head_1x_mixedDataset_loadFromSeparatedFile.py \\\n",
    "--work-dir mmdetection/training_logs_example/fcos_coco_kitti_pedestrian_person_setting_bacth_4_lr_0.01/ \\\n",
    "--cfg-options model.bbox_head.num_classes={number_of_categories} \\\n",
    "data.train.ann_file={path_to_train} \\\n",
    "data.val.ann_file={path_to_val} \\\n",
    "runner.max_epochs=30 \\\n",
    "data.samples_per_gpu=4 \\\n",
    "load_from=mmdetection/pths/fcos/fcos_r50_caffe_fpn_gn-head_1x_coco.pth \\\n",
    "data.train.classes=\"$categories\" \\\n",
    "data.val.classes=\"$categories\" \\\n",
    "data.test.classes=\"$categories\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run mmdetection/tools/test.py \\\n",
    "mmdetection/configs/fcos/fcos_r50_caffe_fpn_gn-head_1x_mixedDataset_loadFromSeparatedFile.py \\\n",
    "mmdetection/training_logs_example/fcos_coco_kitti_pedestrian_person_setting_bacth_4_lr_0.01/latest.pth \\\n",
    "--work-dir mmdetection/training_logs_example/fcos_coco_kitti_pedestrian_person_setting_bacth_4_lr_0.01/ \\\n",
    "--out mmdetection/training_logs_example/fcos_coco_kitti_pedestrian_person_setting_bacth_4_lr_0.01/result_test_person.pkl \\\n",
    "--cfg-options data.test.ann_file={path_to_test} \\\n",
    "model.bbox_head.num_classes={number_of_categories} \\\n",
    "data.samples_per_gpu=4 \\\n",
    "data.train.classes=\"$categories\" \\\n",
    "data.val.classes=\"$categories\" \\\n",
    "data.test.classes=\"$categories\" \\\n",
    "--eval bbox \\\n",
    "--show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open-mmlab",
   "language": "python",
   "name": "open-mmlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
