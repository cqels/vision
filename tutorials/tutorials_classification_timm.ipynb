{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tutorials_classification_timm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osTQZUCg-vQF"
      },
      "source": [
        "# Tutorial: Model Training / Inference based on local/mixed Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ah3BVAA7ALxX"
      },
      "source": [
        "# 0 Configure ENVS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1u2FlUnJ-yv3"
      },
      "source": [
        "!git clone https://github.com/rwightman/pytorch-image-models.git\n",
        "\n",
        "%cd pytorch-image-models/\n",
        "!python -m pip --no-cache-dir install -r requirements.txt\n",
        "!python setup.py develop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSaW9721CXPE"
      },
      "source": [
        "# 1 MixedDataset: Querying, Training and Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxVjBE5SIdXE"
      },
      "source": [
        "## 1.1 Training-Perpartion from local datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkMrRI8ZAqXT"
      },
      "source": [
        "### 1.1.1 Download ImageNette"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raH_Hn-1AyU3"
      },
      "source": [
        "!wget -P ./data/ https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-320.tgz\n",
        "!tar -xf ./data/imagenette2-320.tgz -C ./data/ && rm ./data/imagenette2-320.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eQ9b3K24hO_"
      },
      "source": [
        "### 1.1.2 Download CIFAR-100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2NR4zkb4kI_"
      },
      "source": [
        "!wget -P ./data/ https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
        "!tar -xf ./data/cifar-100-python.tar.gz -C ./data/ && rm ./data/cifar-100-python.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJEngD0C5a9R"
      },
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from tqdm import trange\n",
        "\n",
        "\n",
        "cifar100_python='/content/pytorch-image-models/data/cifar-100-python'\n",
        "cifar100_images='./data/cifar100_images'\n",
        "\n",
        "def unpickle(file):\n",
        "    import pickle\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict_data = pickle.load(fo, encoding='latin1')\n",
        "    return dict_data\n",
        "\n",
        "def save_dirs(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "meta_dict=unpickle(os.path.join(cifar100_python,'meta'))\n",
        "save_dirs(cifar100_images)\n",
        "\n",
        "for data_set in ['train', 'val']:\n",
        "        print('Unpickling {} dataset......'.format(data_set))\n",
        "        for idx, fine_label_name in enumerate(meta_dict['fine_label_names']):\n",
        "            save_dirs(os.path.join(cifar100_images, data_set, fine_label_name))\n",
        "        if data_set == 'val':\n",
        "            data_dict = unpickle(os.path.join(cifar100_python, 'test'))\n",
        "        else:\n",
        "            data_dict = unpickle(os.path.join(cifar100_python, data_set))\n",
        "        data, label = np.array(data_dict['data']).reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1), data_dict['fine_labels']\n",
        "        for i in trange(data.shape[0]):\n",
        "            img = Image.fromarray(data[i])\n",
        "            img.save(os.path.join(cifar100_images,data_set, meta_dict['fine_label_names'][data_dict['fine_labels'][i]], data_dict['filenames'][i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KysHLoRwNsfe"
      },
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "import numpy as np\n",
        "\n",
        "def plot_classes_number(path_to_images):\n",
        "    classes_dir = os.listdir(path_to_images)\n",
        "    all_classes_number = len(classes_dir) \n",
        "    class2number = {}\n",
        "    for class_dir in classes_dir:\n",
        "        class_path =os.path.join(path_to_images, class_dir) \n",
        "        picture_name_sequence =os.listdir(class_path)  \n",
        "        each_class_number = len(picture_name_sequence)  \n",
        "        class2number[class_dir] = each_class_number\n",
        "    list_classname = []\n",
        "    list_classnumber = []\n",
        "    for class_dir in classes_dir:\n",
        "        list_classname.append(class_dir)\n",
        "        list_classnumber.append(class2number[class_dir])\n",
        "    plt.figure(figsize=(22, 8), dpi=300)\n",
        "    width = 1.4\n",
        "    x = np.arange(len(list_classname))\n",
        "    y = np.array(list_classnumber)\n",
        "    plt.bar(x, y, width, align='center')\n",
        "    plt.ylabel(\"Number per Class\")\n",
        "    plt.xlabel(\"Class name\")\n",
        "    plt.title(\"Number of each Class\")\n",
        "    plt.xticks(x, list_classname, size='small', rotation=90)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZQeO_4WCxd2"
      },
      "source": [
        "## 1.2 Training-Preparation from a queried mixed dataset based on VisionKG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gD-e_wQ2jdf_"
      },
      "source": [
        "# install our vision utils\n",
        "#!python -m pip install git+https://github.com/cqels/vision.git --force\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDDSL4k-C-b3"
      },
      "source": [
        "# import SemkgAPI\n",
        "#import json\n",
        "#from vision_utils import semkg_api, data\n",
        "\n",
        "# # query from string\n",
        "\n",
        "# # query from file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gHKXJzujdgB"
      },
      "source": [
        "# import json\n",
        "# import os\n",
        "# from os.path import join as opj\n",
        "# from utils import dataset_split, check_instances_categories, check_download_images\n",
        "\n",
        "\n",
        "# query_string='''#Give me the images containing person and cat\n",
        "# prefix cv:<http://vision.semkg.org/onto/v0.1/>\n",
        "# SELECT DISTINCT ?image\n",
        "# WHERE {\n",
        "#     ?ann1 a cv:Annotation.\n",
        "#     ?ann1 cv:isAnnotationOfImage ?image.\n",
        "#     ?ann1 cv:hasAnnotatedObject ?obj1.\n",
        "#     ?obj1 cv:hasLabel \"person\".\n",
        "#     ?ann2 a cv:Annotation.\n",
        "#     ?ann2 cv:isAnnotationOfImage ?image.\n",
        "#     ?ann2 cv:hasAnnotatedObject ?obj2.\n",
        "#     ?obj2 cv:hasLabel \"cat\".\n",
        "#     ?image cv:hasLocalPath ?localPath.\n",
        "# }\n",
        "# LIMIT 20'''\n",
        "\n",
        "# result=semkg_api.query(query_string)\n",
        "\n",
        "# ROOT_PATH = os.path.abspath('./')\n",
        "# json_f_name = 'test_query_api_image.json'\n",
        "# path_to_anno_mixedDatasets = opj(ROOT_PATH, 'testData/mixedDatasets/imagenette2_tiny/meta/')\n",
        "# path_to_images_mixedDatasets = opj(ROOT_PATH, 'testData/mixedDatasets/imagenette2_tiny/')\n",
        "# os.makedirs(path_to_anno_mixedDatasets, exist_ok=True)\n",
        "# path_to_anno = opj(path_to_anno_mixedDatasets, json_f_name)\n",
        "\n",
        "# with open(path_to_anno, \"w\") as f:\n",
        "#     json.dump(result,f)\n",
        "\n",
        "# check_download_images(result[\"images\"])\n",
        "# categories = [category['name'] for category in result['categories']]\n",
        "# number_of_categories = len(categories)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UD7p4SxEVEv"
      },
      "source": [
        "## 1.3 Set dirs && other params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ag1Ygp20ETq6"
      },
      "source": [
        "import os\n",
        "\n",
        "data_dir = './data/imagenette2-320/' \n",
        "test_images = './data/imagenette2-320/val/'\n",
        "output_training_dir = './output/train/'\n",
        "output_test_dir = './output/test/'\n",
        "num_classes = len(os.listdir(test_images))\n",
        "used_model = 'resnet18'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODMJYRW6D3Qa"
      },
      "source": [
        "## 1.4 Training on the queried mixed dataset or local data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TC_kfJJJRU6L"
      },
      "source": [
        "%run train.py {data_dir} \\\n",
        "--output {output_training_dir} \\\n",
        "--model {used_model} \\\n",
        "--sched 'cosine' \\\n",
        "--epochs=50 \\\n",
        "--color-jitter=0 \\\n",
        "--num-classes {num_classes} \\\n",
        "--amp \\\n",
        "--lr=1e-4 \\\n",
        "--min-lr=1e-8 --warmup-epochs=3 --train-interpolation=bilinear --aa=v0 \\\n",
        "--checkpoint-hist 1 \\\n",
        "--pretrained \\\n",
        "--opt=adamw \\\n",
        "--weight-decay=1e-4 \\\n",
        "--batch-size 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQ8e-m9mD2LB"
      },
      "source": [
        "## 1.5 Verify the checkpoint file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6OarK0bwZo0"
      },
      "source": [
        "all_existed_dirs = [os.path.join(output_training_dir,sub_dir) for sub_dir in os.listdir(output_training_dir) if os.path.isdir(os.path.join(output_training_dir,sub_dir))]\n",
        "latest_output_dir = max(all_existed_dirs, key=os.path.getmtime)\n",
        "checkpoint_file = os.path.join(latest_output_dir, \"model_best.pth.tar\")\n",
        "assert os.path.isfile(checkpoint_file), '{} not exist'.format(checkpoint_file)\n",
        "checkpoint_file = os.path.abspath(checkpoint_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9fXegyy5G-q"
      },
      "source": [
        "## 1.6 Testing on the mixed dataset or local data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkkHWcJ7b882"
      },
      "source": [
        "%run validate.py {test_images} \\\n",
        "--model {used_model} \\\n",
        "--num-classes {num_classes} \\\n",
        "--checkpoint {checkpoint_file}"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}