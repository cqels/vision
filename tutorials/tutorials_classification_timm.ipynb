{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osTQZUCg-vQF"
      },
      "source": [
        "# Tutorial: Model Training / Inference based on local/mixed Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ah3BVAA7ALxX"
      },
      "source": [
        "# 0 Configure ENVS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1u2FlUnJ-yv3"
      },
      "source": [
        "!git clone https://github.com/rwightman/pytorch-image-models.git\n",
        "\n",
        "%cd pytorch-image-models/\n",
        "!python -m pip --no-cache-dir install -r requirements.txt\n",
        "!python setup.py develop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSaW9721CXPE"
      },
      "source": [
        "# 1 MixedDataset: Querying, Training and Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxVjBE5SIdXE"
      },
      "source": [
        "## 1.1 Training-Perpartion from local datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkMrRI8ZAqXT"
      },
      "source": [
        "### 1.1.1 Download ImageNette"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raH_Hn-1AyU3"
      },
      "source": [
        "!wget -P ./data/ https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-320.tgz\n",
        "!tar -xf ./data/imagenette2-320.tgz -C ./data/ && rm ./data/imagenette2-320.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eQ9b3K24hO_"
      },
      "source": [
        "### 1.1.2 Download CIFAR-100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2NR4zkb4kI_"
      },
      "source": [
        "!wget -P ./data/ https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
        "!tar -xf ./data/cifar-100-python.tar.gz -C ./data/ && rm ./data/cifar-100-python.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJEngD0C5a9R"
      },
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from tqdm import trange\n",
        "\n",
        "\n",
        "cifar100_python='/content/pytorch-image-models/data/cifar-100-python'\n",
        "cifar100_images='./data/cifar100_images'\n",
        "\n",
        "def unpickle(file):\n",
        "    import pickle\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict_data = pickle.load(fo, encoding='latin1')\n",
        "    return dict_data\n",
        "\n",
        "def save_dirs(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "meta_dict=unpickle(os.path.join(cifar100_python,'meta'))\n",
        "save_dirs(cifar100_images)\n",
        "\n",
        "for data_set in ['train', 'val']:\n",
        "        print('Unpickling {} dataset......'.format(data_set))\n",
        "        for idx, fine_label_name in enumerate(meta_dict['fine_label_names']):\n",
        "            save_dirs(os.path.join(cifar100_images, data_set, fine_label_name))\n",
        "        if data_set == 'val':\n",
        "            data_dict = unpickle(os.path.join(cifar100_python, 'test'))\n",
        "        else:\n",
        "            data_dict = unpickle(os.path.join(cifar100_python, data_set))\n",
        "        data, label = np.array(data_dict['data']).reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1), data_dict['fine_labels']\n",
        "        for i in trange(data.shape[0]):\n",
        "            img = Image.fromarray(data[i])\n",
        "            img.save(os.path.join(cifar100_images,data_set, meta_dict['fine_label_names'][data_dict['fine_labels'][i]], data_dict['filenames'][i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KysHLoRwNsfe"
      },
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "import numpy as np\n",
        "\n",
        "def plot_classes_number(path_to_images):\n",
        "    classes_dir = os.listdir(path_to_images)\n",
        "    all_classes_number = len(classes_dir)\n",
        "    class2number = {}\n",
        "    for class_dir in classes_dir:\n",
        "        class_path =os.path.join(path_to_images, class_dir)\n",
        "        picture_name_sequence =os.listdir(class_path)\n",
        "        each_class_number = len(picture_name_sequence)\n",
        "        class2number[class_dir] = each_class_number\n",
        "    list_classname = []\n",
        "    list_classnumber = []\n",
        "    for class_dir in classes_dir:\n",
        "        list_classname.append(class_dir)\n",
        "        list_classnumber.append(class2number[class_dir])\n",
        "    plt.figure(figsize=(22, 8), dpi=300)\n",
        "    width = 1.4\n",
        "    x = np.arange(len(list_classname))\n",
        "    y = np.array(list_classnumber)\n",
        "    plt.bar(x, y, width, align='center')\n",
        "    plt.ylabel(\"Number per Class\")\n",
        "    plt.xlabel(\"Class name\")\n",
        "    plt.title(\"Number of each Class\")\n",
        "    plt.xticks(x, list_classname, size='small', rotation=90)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZQeO_4WCxd2"
      },
      "source": [
        "## 1.2 Training-Preparation from a queried mixed dataset based on VisionKG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gD-e_wQ2jdf_"
      },
      "source": [
        "# install our vision utils\n",
        "!python -m pip install git+https://github.com/cqels/vision.git --force"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gHKXJzujdgB"
      },
      "source": [
        "import json\n",
        "import os\n",
        "from os.path import join as opj\n",
        "from torch_model_zoo.utils import dataset_split, check_instances_categories, check_download_images\n",
        "import json\n",
        "from vision_utils import semkg_api, data\n",
        "\n",
        "query_string='''#Give me the images containing bus and pickup-truck\n",
        "PREFIX cv: <http://vision.semkg.org/onto/v0.1/>\n",
        "PREFIX schema: <http://schema.org/>\n",
        "\n",
        "SELECT DISTINCT ?image ?label ?imageName ?labelResource\n",
        "WHERE {\n",
        "    {\n",
        "        SELECT DISTINCT ?image ?label ?imageName ?labelResource\n",
        "        WHERE {\n",
        "            ?image schema:isPartOf / schema:name ?datasetName .\n",
        "            ?image cv:hasAnnotation ?annotation .\n",
        "            ?image schema:name ?imageName.\n",
        "            ?annotation a cv:ClassificationAnnotation.\n",
        "            ?annotation cv:hasLabel ?labelResource .\n",
        "            ?labelResource cv:label \"bus\" .\n",
        "        }\n",
        "        LIMIT 50\n",
        "    }\n",
        "    UNION\n",
        "    {\n",
        "        SELECT DISTINCT ?image ?label ?imageName ?labelResource\n",
        "        WHERE {\n",
        "            ?image schema:isPartOf / schema:name ?datasetName .\n",
        "            ?image cv:hasAnnotation ?annotation .\n",
        "            ?image schema:name ?imageName.\n",
        "            ?annotation a cv:ClassificationAnnotation.\n",
        "            ?annotation cv:hasLabel ?labelResource .\n",
        "            ?labelResource cv:label \"pickup_truck\" .\n",
        "        }\n",
        "        LIMIT 50\n",
        "    }\n",
        "}\n",
        "'''\n",
        "\n",
        "result=semkg_api.query(query_string)\n",
        "ROOT_PATH = os.path.abspath('./')\n",
        "json_f_name = 'test_query_api_image.json'\n",
        "path_to_anno_mixedDatasets = opj(ROOT_PATH, 'testData/mixedDatasets/vkg/meta/')\n",
        "path_to_images_mixedDatasets = opj(ROOT_PATH, 'testData/mixedDatasets/vkg/')\n",
        "os.makedirs(path_to_anno_mixedDatasets, exist_ok=True)\n",
        "path_to_anno = opj(path_to_anno_mixedDatasets, json_f_name)\n",
        "\n",
        "with open(path_to_anno, \"w\") as f:\n",
        "    json.dump(result,f)\n",
        "query_results = {'images': ['https://vision-api.semkg.org/api/view?image=/' + i['labelResource'].split(os.sep)[-2] + os.sep + i['imageName'] for i in result],\n",
        "                 'categories': [i['labelResource'].split(os.sep)[-1] for i in result]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import urllib.request\n",
        "import time\n",
        "\n",
        "def create_classmap(categories):\n",
        "    unique_categories = sorted(set(categories))\n",
        "    return {category: i for i, category in enumerate(unique_categories)}\n",
        "\n",
        "def pull_vkg_images(images, categories, base_folder, classmap):\n",
        "    save_dir = os.path.dirname(base_folder)\n",
        "    txt_filename = os.path.join(save_dir, 'train.txt' if 'train' in base_folder else 'val.txt')\n",
        "    with open(txt_filename, 'w') as txt_file:\n",
        "        for url, category in zip(images, categories):\n",
        "            folder = os.path.join(base_folder, category)\n",
        "            if not os.path.exists(folder):\n",
        "                os.makedirs(folder)\n",
        "            filename = os.path.join(folder, url.split('/')[-1])\n",
        "            time.sleep(1)\n",
        "            urllib.request.urlretrieve(url, filename)\n",
        "            txt_file.write(f\"{os.path.join('train' if 'train' in base_folder else 'val', category, url.split('/')[-1])} {classmap[category]}\\n\")\n",
        "\n",
        "train_images, test_images, train_categories, test_categories = train_test_split(\n",
        "    query_results['images'], query_results['categories'], test_size=0.2, stratify=query_results['categories'])\n",
        "classmap = create_classmap(query_results['categories'])\n",
        "pull_vkg_images(train_images, train_categories, opj(path_to_images_mixedDatasets, 'train'), classmap)\n",
        "pull_vkg_images(test_images, test_categories, opj(path_to_images_mixedDatasets, 'val'), classmap)\n",
        "with open(os.path.join(path_to_images_mixedDatasets, 'classmap.txt'), 'w') as map_file:\n",
        "    for category, num in classmap.items():\n",
        "        map_file.write(f\"{category} {num}\\n\")"
      ],
      "metadata": {
        "id": "c5WAvxuxTzy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UD7p4SxEVEv"
      },
      "source": [
        "## 1.3 Set dirs && other params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ag1Ygp20ETq6"
      },
      "source": [
        "import os\n",
        "\n",
        "data_dir = path_to_images_mixedDatasets\n",
        "test_images = opj(path_to_images_mixedDatasets, 'val')\n",
        "output_training_dir = './output/train/'\n",
        "output_test_dir = './output/test/'\n",
        "num_classes = len(os.listdir(test_images))\n",
        "used_model = 'resnet18'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODMJYRW6D3Qa"
      },
      "source": [
        "## 1.4 Training on the queried mixed dataset or local data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TC_kfJJJRU6L"
      },
      "source": [
        "%run train.py {data_dir} \\\n",
        "--data-dir {data_dir} \\\n",
        "--output {output_training_dir} \\\n",
        "--model {used_model} \\\n",
        "--sched 'cosine' \\\n",
        "--epochs=50 \\\n",
        "--color-jitter=0 \\\n",
        "--num-classes {num_classes} \\\n",
        "--amp \\\n",
        "--lr=1e-4 \\\n",
        "--min-lr=1e-8 --warmup-epochs=3 --train-interpolation=bilinear --aa=v0 \\\n",
        "--checkpoint-hist 1 \\\n",
        "--pretrained \\\n",
        "--opt=adamw \\\n",
        "--weight-decay=1e-4 \\\n",
        "--batch-size 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQ8e-m9mD2LB"
      },
      "source": [
        "## 1.5 Verify the checkpoint file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6OarK0bwZo0"
      },
      "source": [
        "all_existed_dirs = [os.path.join(output_training_dir,sub_dir) for sub_dir in os.listdir(output_training_dir) if os.path.isdir(os.path.join(output_training_dir,sub_dir))]\n",
        "latest_output_dir = max(all_existed_dirs, key=os.path.getmtime)\n",
        "checkpoint_file = os.path.join(latest_output_dir, \"model_best.pth.tar\")\n",
        "assert os.path.isfile(checkpoint_file), '{} not exist'.format(checkpoint_file)\n",
        "checkpoint_file = os.path.abspath(checkpoint_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9fXegyy5G-q"
      },
      "source": [
        "## 1.6 Testing on the mixed dataset or local data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkkHWcJ7b882"
      },
      "source": [
        "%run validate.py {test_images} \\\n",
        "--model {used_model} \\\n",
        "--num-classes {num_classes} \\\n",
        "--checkpoint {checkpoint_file}"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}