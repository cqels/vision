{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Tutorials_VisionKG_Pytorch_Build-in-Models.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osTQZUCg-vQF"
      },
      "source": [
        "# Tutorial: VisionKG - A Data-Centric Way to Train your own Obejct Detection Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHWnyaMpSECR"
      },
      "source": [
        "# 1. QuickView of VisionKG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xs9SW55g6R2t"
      },
      "source": [
        "## 1.1 One-Click to meet VisionKG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCW61IUV6R2v"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from google.colab import output\n",
        "# install our vision api\n",
        "!python -m pip install git+https://github.com/cqels/vision.git --force\n",
        "output.clear()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZQeO_4WCxd2"
      },
      "source": [
        "## 1.2 Query a Dataset as YOU need via VisionKG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gHKXJzujdgB"
      },
      "source": [
        "# import SemkgAPI\n",
        "from vision_utils import semkg_api, data\n",
        "from skimage import io\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "query_string='''#Give me 100 images containing car and truck\n",
        "prefix cv:<http://vision.semkg.org/onto/v0.1/>\n",
        "SELECT DISTINCT ?image\n",
        "WHERE {\n",
        "    ?ann1 a cv:Annotation.\n",
        "    ?ann1 cv:isAnnotationOfImage ?image.\n",
        "    ?ann1 cv:hasAnnotatedObject ?obj1.\n",
        "    ?obj1 cv:hasLabel \"car\".\n",
        "    ?ann2 a cv:Annotation.\n",
        "    ?ann2 cv:isAnnotationOfImage ?image.\n",
        "    ?ann2 cv:hasAnnotatedObject ?obj2.\n",
        "    ?obj2 cv:hasLabel \"truck\".\n",
        "    ?image cv:hasLocalPath ?localPath.\n",
        "}\n",
        "LIMIT 100'''\n",
        "\n",
        "#Query and return result\n",
        "result=semkg_api.query(query_string)\n",
        "\n",
        "\n",
        "#Display sample images\n",
        "rows=3\n",
        "cols=4\n",
        "f, ax_arr = plt.subplots(rows, cols, figsize=(16,8))\n",
        "for j, row in enumerate(ax_arr):\n",
        "    for i, ax in enumerate(row):\n",
        "        if j*cols+i < len(result['images']):\n",
        "            image = io.imread(semkg_api.SEMKG_IMAGES_HOST + result['images'][j*cols+i]['image_path'])\n",
        "            ax.imshow(image)\n",
        "\n",
        "f.suptitle(\"Sample images from the query result\", fontsize=16)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSaW9721CXPE"
      },
      "source": [
        "# 2. Object Detection in Practice starting from VisionKG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZ4e_tlQ6R20"
      },
      "source": [
        "## 2.1 Prepare and set parameters for training and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIs9RHdcHF77"
      },
      "source": [
        "from torch_model_zoo import utils\n",
        "from os.path import join as opj\n",
        "\n",
        "path_to_anno_mixedDatasets = opj('data/mixedDatasets/','test_query_api_image.json')\n",
        "params = utils.prepare_for_training(path_to_anno_mixedDatasets, result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfFluzqk6R2n"
      },
      "source": [
        "##2.2 Dataset Playground"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnNra7YcvutW"
      },
      "source": [
        "if num_categories > 4:\n",
        "  cat_nms = nms_categories[0:4]\n",
        "else:\n",
        "  cat_nms = nms_categories\n",
        "  \n",
        "utils.show_annotation(path_to_anno_mixedDatasets, cat_nms, show_num=6)\n",
        "utils.show_cat_distribution(path_to_anno_mixedDatasets, cat_nms)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ob5OoeS9JIiO"
      },
      "source": [
        "## 2.3 Perform Training & Evaluation on pytorch build-in models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcUjrc23IiBC"
      },
      "source": [
        "from torch_model_zoo.train_eval import train_eval_pipeline\n",
        "\n",
        "train_eval_pipeline(params)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}