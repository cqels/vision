{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "tutorials_detection_mmdetection(2)(10).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osTQZUCg-vQF"
      },
      "source": [
        "# Tutorial: VisionKG - A Data-Centric Way to Train your own Obejct Detection Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHWnyaMpSECR"
      },
      "source": [
        "# 1. QuickView of VisionKG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xs9SW55g6R2t"
      },
      "source": [
        "## 1.1 One-Click to meet VisionKG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCW61IUV6R2v"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from google.colab import output\n",
        "# install our vision api\n",
        "!python -m pip install git+https://github.com/cqels/vision.git --force\n",
        "output.clear()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZQeO_4WCxd2"
      },
      "source": [
        "## 1.2 Query a Dataset as YOU need via VisionKG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gHKXJzujdgB"
      },
      "source": [
        "# import SemkgAPI\n",
        "from vision_utils import semkg_api, data\n",
        "from skimage import io\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "query_string='''#Give me 100 images containing person and cat\n",
        "prefix cv:<http://vision.semkg.org/onto/v0.1/>\n",
        "SELECT DISTINCT ?image\n",
        "WHERE {\n",
        "    ?ann1 a cv:Annotation.\n",
        "    ?ann1 cv:isAnnotationOfImage ?image.\n",
        "    ?ann1 cv:hasAnnotatedObject ?obj1.\n",
        "    ?obj1 cv:hasLabel \"person\".\n",
        "    ?ann2 a cv:Annotation.\n",
        "    ?ann2 cv:isAnnotationOfImage ?image.\n",
        "    ?ann2 cv:hasAnnotatedObject ?obj2.\n",
        "    ?obj2 cv:hasLabel \"cat\".\n",
        "    ?image cv:hasLocalPath ?localPath.\n",
        "}\n",
        "LIMIT 100'''\n",
        "\n",
        "#Query and return result\n",
        "result=semkg_api.query(query_string)\n",
        "\n",
        "\n",
        "#Display sample images\n",
        "rows=3\n",
        "cols=4\n",
        "f, ax_arr = plt.subplots(rows, cols, figsize=(16,8))\n",
        "for j, row in enumerate(ax_arr):\n",
        "    for i, ax in enumerate(row):\n",
        "        if j*cols+i < len(result['images']):\n",
        "            image = io.imread(semkg_api.SEMKG_IMAGES_HOST + result['images'][j*cols+i]['image_path'])\n",
        "            ax.imshow(image)\n",
        "\n",
        "f.suptitle(\"Sample images from the query result\", fontsize=16)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSaW9721CXPE"
      },
      "source": [
        "# 2. Object Detection in Practice starting from VisionKG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfFluzqk6R2n"
      },
      "source": [
        "##2.1 VisionKG meet mmdetection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ultNaE1kSECU"
      },
      "source": [
        "# clone the toolbox for object detection\n",
        "!git clone https://github.com/open-mmlab/mmdetection.git\n",
        "\n",
        "# install dependencies\n",
        "%cd mmdetection/\n",
        "!python -m pip install -r requirements.txt\n",
        "!python -m pip install mmcv-full==1.3.14 -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.9.0/index.html\n",
        "!python setup.py develop\n",
        "\n",
        "output.clear()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZ4e_tlQ6R20"
      },
      "source": [
        "## 2.2 Prepare and set parameters for training and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38x2pe0OSECd"
      },
      "source": [
        "from os.path import join as opj\n",
        "from shutil import copy\n",
        "from torch_model_zoo import utils\n",
        "from mmdetection_configs import configs_fcos_visionKG\n",
        "\n",
        "path_to_anno_mixedDatasets = opj('data/mixedDatasets/','test_query_api_image.json')\n",
        "filter_cat_nms = ['person', 'cat']\n",
        "params = utils.prepare_for_training(path_to_anno_mixedDatasets, result, filter_cat_nms)\n",
        "path_to_config = 'configs/fcos/fcos_visionKG.py'\n",
        "path_to_work_dir = 'mixedDatasets/logs_visionKG/'\n",
        "copy(configs_fcos_visionKG.__file__, path_to_config)\n",
        "nms_categories = params['CAT_NMS']\n",
        "num_categories = len(nms_categories)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwujjB2hLyk_"
      },
      "source": [
        "##2.3 Data-Playground"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSxR5mGTL1Cg"
      },
      "source": [
        "if num_categories > 4:\n",
        "  cat_nms = nms_categories[0:4]\n",
        "else:\n",
        "  cat_nms = nms_categories\n",
        "utils.show_annotation(path_to_anno_mixedDatasets, cat_nms, show_num=6)\n",
        "utils.show_cat_distribution(path_to_anno_mixedDatasets, cat_nms)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HNbl_TRC5q8"
      },
      "source": [
        "## 2.4 Perform Training & Evaluation on your chosen Object Detection tool"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6E_Vv_OVQHV"
      },
      "source": [
        "# Training based on the queried MixedDataset\n",
        "# For more params-setting, please check: \n",
        "# https://mmdetection.readthedocs.io/en/latest/\n",
        "%run tools/train.py {path_to_config} \\\n",
        "--cfg-options model.bbox_head.num_classes={num_categories} \\\n",
        "data.train.classes=\"$nms_categories\" data.val.classes=\"$nms_categories\"\n",
        "\n",
        "# Evaluate the trained model on the MixedDataset\n",
        "checkpoint_file = utils.checkpoint_verify(path_to_work_dir)\n",
        "%run tools/test.py {path_to_config} {checkpoint_file} \\\n",
        "--options \"classwise=True\" \\\n",
        "--cfg-options model.bbox_head.num_classes={num_categories} \\\n",
        "data.test.classes=\"$nms_categories\" --eval bbox --show"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nouKewLRRhR"
      },
      "source": [
        "# Training based on the queried MixedDataset\n",
        "# For more params-setting, please check: \n",
        "# https://mmdetection.readthedocs.io/en/latest/\n",
        "%run tools/train.py {path_to_config} \\\n",
        "--cfg-options model.bbox_head.num_classes={num_categories} \\\n",
        "data.train.classes=\"$nms_categories\" data.val.classes=\"$nms_categories\"\n",
        "\n",
        "# Evaluate the trained model on the MixedDataset\n",
        "checkpoint_file = utils.checkpoint_verify(path_to_work_dir)\n",
        "%run tools/test.py {path_to_config} {checkpoint_file} \\\n",
        "--options \"classwise=True\" \\\n",
        "--cfg-options model.bbox_head.num_classes={num_categories} \\\n",
        "data.test.classes=\"$nms_categories\" --eval bbox --show"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}