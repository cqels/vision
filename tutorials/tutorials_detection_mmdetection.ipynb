{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osTQZUCg-vQF"
      },
      "source": [
        "# Tutorial: VisionKG - A Data-Centric Way to Train your own Obejct Detection Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHWnyaMpSECR"
      },
      "source": [
        "# 1. QuickView of VisionKG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xs9SW55g6R2t"
      },
      "source": [
        "## 1.1. One-Click to meet VisionKG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCW61IUV6R2v"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from google.colab import output\n",
        "# install our vision api\n",
        "!python -m pip install git+https://github.com/cqels/vision.git --force\n",
        "output.clear()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZQeO_4WCxd2"
      },
      "source": [
        "## 1.2 Query a Dataset as YOU need via VisionKG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gHKXJzujdgB"
      },
      "outputs": [],
      "source": [
        "# import SemkgAPI\n",
        "from vision_utils import semkg_api, data\n",
        "from IPython.display import Image, display\n",
        "\n",
        "query_string='''#Give me the images containing person and cat\n",
        "prefix cv:<http://vision.semkg.org/onto/v0.1/>\n",
        "SELECT DISTINCT ?image\n",
        "WHERE {\n",
        "    ?ann1 a cv:Annotation.\n",
        "    ?ann1 cv:isAnnotationOfImage ?image.\n",
        "    ?ann1 cv:hasAnnotatedObject ?obj1.\n",
        "    ?obj1 cv:hasLabel \"person\".\n",
        "    ?ann2 a cv:Annotation.\n",
        "    ?ann2 cv:isAnnotationOfImage ?image.\n",
        "    ?ann2 cv:hasAnnotatedObject ?obj2.\n",
        "    ?obj2 cv:hasLabel \"cat\".\n",
        "    ?image cv:hasLocalPath ?localPath.\n",
        "}\n",
        "LIMIT 100'''\n",
        "\n",
        "result=semkg_api.query(query_string)\n",
        "\n",
        "print(\"Sample images from the query result\")\n",
        "for i in range(3):\n",
        "    image = result['images'][i]\n",
        "    display(Image(semkg_api.SEMKG_IMAGES_HOST + image['image_path'] , width=400))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSaW9721CXPE"
      },
      "source": [
        "# 2. Object Detection in Practice starting from VisionKG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfFluzqk6R2n"
      },
      "source": [
        "##2.1. VisionKG meet mmdetection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ultNaE1kSECU"
      },
      "outputs": [],
      "source": [
        "# clone the toolbox for object detection\n",
        "!git clone https://github.com/jichengyuan/mmdetectionCust.git\n",
        "\n",
        "# install dependencies\n",
        "%cd mmdetectionCust/\n",
        "!python -m pip install cython funcy && python -m pip install -r requirements.txt\n",
        "!python -m pip install mmcv-full==1.3.14 -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.9.0/index.html\n",
        "!python setup.py develop\n",
        "\n",
        "output.clear()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZ4e_tlQ6R20"
      },
      "source": [
        "## 2.2 Load your customized Dataset from local Disk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38x2pe0OSECd"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from os.path import join as opj\n",
        "from utils import check_download_images\n",
        "# save query result\n",
        "path_to_anno_mixedDatasets = opj('data/mixedDatasets/',\n",
        "                                 'test_query_api_image.json')\n",
        "with open(path_to_anno_mixedDatasets, \"w\") as f:\n",
        "    json.dump(result,f)\n",
        "# check images queried from VisionKG\n",
        "check_download_images(result[\"images\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HNbl_TRC5q8"
      },
      "source": [
        "## 2.3 Perform Training & Evaluation on your chosen Object Detection tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nouKewLRRhR"
      },
      "outputs": [],
      "source": [
        "from utils import dataset_split, checkpoint_verify\n",
        "\n",
        "# Split the quried MixedDatasets and check the #instances per category\n",
        "ratio = 0.8\n",
        "train_val_test = ['train.json','val.json','test.json']\n",
        "dataset_split(path_to_anno_mixedDatasets, train_val_test, ratio)\n",
        "nms_categories = [category['name'] for category in result['categories']]\n",
        "num_categories = len(nms_categories)\n",
        "\n",
        "# Set paths for config and work-dir\n",
        "path_to_config = 'configs/fcos/fcos_visionKG.py'\n",
        "path_to_work_dir = 'mixedDatasets/logs_visionKG/'\n",
        "\n",
        "# Training based on the queried MixedDataset\n",
        "# For more params-setting, please check: \n",
        "# https://mmdetection.readthedocs.io/en/latest/\n",
        "%run tools/train.py {path_to_config} \\\n",
        "--work-dir {path_to_work_dir} \\\n",
        "--cfg-options model.bbox_head.num_classes={num_categories} \\\n",
        "data.train.classes=\"$nms_categories\" data.val.classes=\"$nms_categories\"\n",
        "\n",
        "# Verify the checkpoint file.\n",
        "checkpoint_file = checkpoint_verify(path_to_work_dir)\n",
        "\n",
        "# Evaluate the trained model on the MixedDataset\n",
        "%run tools/test.py {path_to_config} {checkpoint_file} \\\n",
        "--work-dir {path_to_work_dir} \\\n",
        "--cfg-options model.bbox_head.num_classes={num_categories} \\\n",
        "data.test.classes=\"$nms_categories\" --eval bbox --show"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "tutorials_detection_mmdetection(2).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
