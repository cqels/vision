{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osTQZUCg-vQF"
      },
      "source": [
        "# Tutorial: VisionKG - A Data-Centric Way to Train your own Obejct Detection Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHWnyaMpSECR"
      },
      "source": [
        "# 1. QuickView of VisionKG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xs9SW55g6R2t"
      },
      "source": [
        "## 1.1 One-Click to meet VisionKG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCW61IUV6R2v"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from google.colab import output\n",
        "# install our vision api\n",
        "!python -m pip install git+https://github.com/cqels/vision.git --force\n",
        "output.clear()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZQeO_4WCxd2"
      },
      "source": [
        "## 1.2 Query a Dataset as YOU need via VisionKG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gHKXJzujdgB"
      },
      "outputs": [],
      "source": [
        "# import SemkgAPI\n",
        "from vision_utils import semkg_api, data\n",
        "from skimage import io\n",
        "import matplotlib.pyplot as plt\n",
        "from torch_model_zoo import utils\n",
        "\n",
        "query_string='''# Give me 100 images contain Car and Pedestrian with its annotations.\n",
        "PREFIX cv:<http://vision.semkg.org/onto/v0.1/>\n",
        "PREFIX schema:<http://schema.org/>\n",
        "PREFIX rdf:<http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
        "PREFIX xsd:<http://www.w3.org/2001/XMLSchema#>\n",
        "SELECT ?datasetName (STR(?_imageName) AS ?imageName) ?imageUrl (xsd:integer(?_imageWidth) AS ?imageWidth) (xsd:integer(?_imageHeight) AS ?imageHeight) ?labelName ?bbCentreX ?bbCentreY ?bbWidth ?bbHeight\n",
        "WHERE {\n",
        "  {\n",
        "    SELECT ?image\n",
        "    WHERE{\n",
        "      ?image cv:hasAnnotation ?annotation1.\n",
        "      ?annotation1 a cv:ObjectDetectionAnnotation.\n",
        "      ?annotation1 cv:hasLabel ?label1.\n",
        "      ?label1 cv:label \"car\".\n",
        "\n",
        "      ?image cv:hasAnnotation ?annotation2.\n",
        "      ?annotation2 a cv:ObjectDetectionAnnotation.\n",
        "      ?annotation2 cv:hasLabel ?label2.\n",
        "      ?label2 cv:label \"person\".\n",
        "\n",
        "      ?image schema:isPartOf / schema:name ?datasetName .\n",
        "      FILTER regex(?datasetName, \"coco2017\", \"i\")\n",
        "    }\n",
        "    GROUP BY ?image\n",
        "    LIMIT 100\n",
        "  }\n",
        "  ?image schema:isPartOf / schema:name ?datasetName .\n",
        "  ?image schema:name ?_imageName.\n",
        "  OPTIONAL{?image schema:contentUrl ?imageUrl}.\n",
        "  ?image cv:hasAnnotation ?annotation.\n",
        "  ?image cv:imgWidth ?_imageWidth.\n",
        "  ?image cv:imgHeight ?_imageHeight.\n",
        "  ?annotation cv:hasLabel/cv:label ?labelName.\n",
        "  ?annotation cv:hasBox ?bbox.\n",
        "  ?bbox cv:boxHeight ?bbHeight.\n",
        "  ?bbox cv:boxWidth ?bbWidth.\n",
        "  ?bbox cv:centerX ?bbCentreX.\n",
        "  ?bbox cv:centerY ?bbCentreY.\n",
        "}\n",
        "'''\n",
        "\n",
        "#Query and return result\n",
        "result=semkg_api.query(query_string)\n",
        "result = utils.visionkg2cocoDet(result)\n",
        "\n",
        "# #Display sample images\n",
        "# rows=3\n",
        "# cols=4\n",
        "# f, ax_arr = plt.subplots(rows, cols, figsize=(16,8))\n",
        "# for j, row in enumerate(ax_arr):\n",
        "#     for i, ax in enumerate(row):\n",
        "#         if j*cols+i < len(result['images']):\n",
        "#             image = io.imread(semkg_api.SEMKG_IMAGES_HOST + result['images'][j*cols+i]['image_path'])\n",
        "#             ax.imshow(image)\n",
        "\n",
        "# f.suptitle(\"Sample images from the query result\", fontsize=16)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSaW9721CXPE"
      },
      "source": [
        "# 2. Object Detection in Practice starting from VisionKG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfFluzqk6R2n"
      },
      "source": [
        "##2.1 VisionKG meet mmdetection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ultNaE1kSECU"
      },
      "outputs": [],
      "source": [
        "# clone the toolbox for object detection\n",
        "!git clone https://github.com/open-mmlab/mmdetection.git\n",
        "\n",
        "# install dependencies\n",
        "%cd mmdetection/\n",
        "!python -m pip install -r requirements.txt\n",
        "!python -m pip install mmcv==2.1.0 -f https://download.openmmlab.com/mmcv/dist/cu121/torch2.1/index.html\n",
        "!python setup.py develop\n",
        "\n",
        "output.clear()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZ4e_tlQ6R20"
      },
      "source": [
        "## 2.2 Prepare and set parameters for training and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38x2pe0OSECd"
      },
      "outputs": [],
      "source": [
        "from os.path import join as opj\n",
        "from shutil import copy\n",
        "from torch_model_zoo import utils\n",
        "from mmdetection_configs import configs_fcos_visionKG\n",
        "\n",
        "path_to_anno_mixedDatasets = opj('data/mixedDatasets/','test_query_api_image.json')\n",
        "filter_cat_nms = ['person', 'car']\n",
        "params = utils.prepare_for_training(path_to_anno_mixedDatasets, result, filter_cat_nms)\n",
        "path_to_config = 'configs/fcos/fcos_visionKG.py'\n",
        "path_to_work_dir = 'mixedDatasets/logs_visionKG/'\n",
        "copy(configs_fcos_visionKG.__file__, path_to_config)\n",
        "nms_categories = params['CAT_NMS']\n",
        "num_categories = len(nms_categories)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwujjB2hLyk_"
      },
      "source": [
        "##2.3 Data-Playground"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSxR5mGTL1Cg"
      },
      "outputs": [],
      "source": [
        "if num_categories > 4:\n",
        "  cat_nms = nms_categories[0:4]\n",
        "else:\n",
        "  cat_nms = nms_categories\n",
        "utils.show_annotation(path_to_anno_mixedDatasets, cat_nms, show_num=6)\n",
        "utils.show_cat_distribution(path_to_anno_mixedDatasets, cat_nms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HNbl_TRC5q8"
      },
      "source": [
        "## 2.4 Perform Training & Evaluation on your chosen Object Detection tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6E_Vv_OVQHV"
      },
      "outputs": [],
      "source": [
        "# Training based on the queried MixedDataset\n",
        "# For more params-setting, please check:\n",
        "# https://mmdetection.readthedocs.io/en/latest/\n",
        "%run tools/train.py {path_to_config} \\\n",
        "--cfg-options model.bbox_head.num_classes={num_categories} \\\n",
        "train_dataloader.dataset.metainfo.classes=\"$nms_categories\" val_dataloader.dataset.metainfo.classes=\"$nms_categories\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "tutorials_detection_mmdetection(2)(10).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "visionkg-datasets",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "d034eb8964615eb9f1f299ed9ec7ff05e43fa738e98a29e50204350da442bfaf"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}